library(argparse)
library(data.table)
library(stringr)
library(parallel)
library(DEXSeq)
library(edgeR)
library(Rsamtools)
library(handy)
library(GenomicRanges)
library(gsubfn)

# Method: ChIPSeq FASTQ reads (75 bp single-end read) are converted to BAM via ENCODE pipeline (May 2018) with all default parameters suggested in the developers except that an option 'histone' is applied to samples generated by H3AC27AC and polymerase2 antibodies. ENCODE uses BWA single-end mode and refines the quality of mapping by collapsing duplicated reads and relying on uniquely mapped reads (e.g., mean MAPQ score 37). For an alignment visualization, the BAM file converts to UCSC bigwig file format with bin_size = 1 via deepTools (bamCoverage 3.0.2-1-ac193610). In order to make the visual mapping consistent with DESeq2 analysis, we apply a scaling factor which is a ratio of normalized read count to a raw read counts reported DESeq2 analysis during the conversion process.
        
b37_chroms <- function () 
{
  paste(c(1:22, "X", "Y", "MT"), sep = "")
}

# --------------------------------------------------------------------
# Append BAM file paths into Experiment Sheet
appendBamFilePath <- function(exp_sheet_fn,bam_dir,bam_suffix=".bam")
{
  exp_sheet <- fread(file=exp_sheet_fn,sep=',',header = TRUE)
  bams <- dir(bam_dir,pattern=sprintf('%s$',bam_suffix),full.names=T)
  samples <- str_replace(str_replace(bams,".*/",""),bam_suffix,"")
  bam_dt <- data.table(sample=samples,bam=bams)
  return(merge(exp_sheet,bam_dt,by='sample',all.x=TRUE,in_place=TRUE))
}

# --------------------------------------------------------------------
# Load in Sample CSV
readSampleInfo <- function(file,colors=NULL)
{
  if(is.null(file)){stop("Must provide a path to a file to open.")}
  if(!file.exists(file)){stop(paste("Could not open: ",file,sep=""))}
  samplesheet <- read.csv(file, header=TRUE, stringsAsFactors=FALSE)
  if(sum(c("sample","group","bam") %in% colnames(samplesheet))!=3){stop("CSV must contain columns: sample, group, bam")}
  nsamp <- nrow(samplesheet)
  ngroup <- length(unique(samplesheet$group))
  message(paste("Found ", nsamp, " samples in ", ngroup, " groups",sep=""))
  grouporder <- unique(samplesheet$group)
  samplesheet$group <- factor(samplesheet$group,levels=grouporder,ordered=TRUE)
  message(paste("Group order detected as: ", paste(grouporder,collapse=", ", sep=""), sep=""))
  message("Number of samples in each group:")
  print(summary(samplesheet$group))
  samplesheet <- samplesheet[order(samplesheet$group,samplesheet$sample),]
  if(is.null(colors) & sum(colnames(samplesheet)=="color")==0)
  {
    message("Auto-picking group colors from RColorBrewer")
    if(ngroup<=9)
    {
      colors <- RColorBrewer::brewer.pal(ngroup,"Set1")
    } else
    {
      colors <- colorRampPalette(brewer.pal(9,"Set1"))(ngroup)
    }
    samplesheet$color <- colors[as.numeric(samplesheet$group)]
  } else if(!is.null(colors))
  {
    if(length(colors)!=ngroup){stop("colors vector must equal number of groups in file")}
    samplesheet$color <- colors[as.numeric(samplesheet$group)]
  }
  samplesheet	
}

# --------------------------------------------------------------------
# Load BAMs to RAM
getReads <- function(samp, chrs, ncore) {
  message("Reading BAMs from disk with ",ncore," concurrent processes")
  # Validate BAM existence
  # Check that BAM files exist
  check <- sapply(samp$bam,file.exists)
  if(sum(check)!=nrow(samp)){stop(paste0("BAM file(s) could not be found: ",toString(samp$bam[check==F])))}
  
  # Check BAIs exist
  check <- sapply(paste0(samp$bam,".bai"),file.exists)
  if(sum(check)!=nrow(samp)){stop(paste0("Bam Index (.bai) file(s) could not be found for: ",toString(samp$bam[check==F])))}
  
  # Validate asked for chrs are in the BAM
  b1 <- Rsamtools::BamFile(samp$bam[1])
  sl <- seqlengths(b1)
  if(sum(chrs %in% seqlevels(b1)) != length(chrs)){stop(paste0("Could not find chrs: ",toString(chrs[!(chrs %in% seqlevels(b1))]), " in given BAM header"))}
  
  # Use the index so we don't bother reading in from the unaligned chrs
  which.gr <- GRanges(chrs,IRanges(1,seqlengths(b1)[chrs]))
  
  bam2gr <- function(bampath) {
    message("Reading BAM file: ",bampath)
    # What: fields to read in (column filtering)
    # Flag: records to read in (row filtering)
    # Which: what sequences must be overlaped (chr/pos filtering)
    param <- Rsamtools::ScanBamParam(what=character(), which=which.gr, flag=Rsamtools::scanBamFlag(isUnmappedQuery=FALSE))
    bam.ga <- GenomicAlignments::readGAlignments(bampath, param = param)
    bam.gr <- as(bam.ga, "GRanges")
    seqlevels(bam.gr) <- chrs
    seqlengths(bam.gr) <- sl[chrs]
    return(bam.gr)
  }
  reads <- mclapply(samp$bam,bam2gr,mc.cores=ncore)
  names(reads) <- samp$sample
  message("Read GRanges Size in Memory=",format(object.size(reads),units="auto"))
  return(reads)
}

# --------------------------------------------------------------------
# Create genomic coverage WIG files
saveCov_compare <- function(samp,reads,out_track_dir=".",bigwig=FALSE,server=NULL,ncore=1, track_suffix=NULL, wigToBigWig_opt="") {
  
  # browser()
  
  if(!dir.exists(out_track_dir)) {
    dir.create(out_track_dir,recursive=TRUE)
  }
  
  if((!is.null(server))&(bigwig==TRUE)) {
    if (!is.null(track_suffix)) {
      track_fn <- sprintf("tracks_%s.txt",track_suffix)
    } else {
      track_fn <- sprintf("tracks.txt")
    }
    trackpath <- file.path(out_track_dir,track_fn)
    
    message("Saving tracklist to ",trackpath)
    rgbs <- str_replace_all(apply(col2rgb(samp$color),2,toString)," ","")
    
    head_raw_tracks <- sprintf("track type=bigWig name=\"%s\" visivility=full maxHeightPiexels=50 color=%s autoScale=off viewLimits=0:30 bigDataUrl=%s.bw",names(reads),rep(rgbs,each=1),file.path(server,names(reads)))
    
    head_scaled_tracks <- sprintf("track type=bigWig name=\"%s(scaled)\" visivility=full maxHeightPiexels=50 color=%s autoScale=off viewLimits=0:30 bigDataUrl=%s_scaled.bw",names(reads),rep(rgbs,each=1),file.path(server,names(reads)))
    
    writeLines(c(head_raw_tracks,head_scaled_tracks),trackpath)
  }

  message("Computing genome-wide coverage vectors")
  cov <- mclapply(reads,coverage,mc.cores=ncore)
  
  message("Assembling to GRanges")
  covgr <- mclapply(cov,function(x) as(x,"GRanges"),mc.cores=ncore)
  covgr1 <- lapply(covgr,function(x) x[x$score>0,])
  
  # get lib size factor via DESeq2 method
  message("Performing sizeFactor normalization via DESeq2")
  libsizes <- sapply(reads,length)
  cnt <- matrix(libsizes,nrow=1)
  colnames(cnt) <- names(libsizes)
  sizefactors <- estimateSizeFactorsForMatrix(cnt)
  
  # Normalize via sizefactors
  covgr1.norm <- covgr1
  
  ctrl_samp <- samp[label=='ctrl',sample]
  expr_samp <- samp[label=='expr',sample]
  
  for (sample_label in expr_samp) {
    covgr1[[sample_label]]$score <- -1.0*covgr1[[sample_label]]$score
    covgr1.norm[[sample_label]]$score <- -1.0*covgr1.norm[[sample_label]]$score/sizefactors[[sample_label]]
  }
  
  for (sample_label in ctrl_samp) {
    covgr1.norm[[sample_label]]$score <- covgr1.norm[[sample_label]]$score/sizefactors[[sample_label]]
  }

  chrs <- seqlevels(reads[[1]])
  chrlens <- seqlengths(reads[[1]])
  
  writeBed <- function(gr,name) {
    message(paste(name,": Creating BedGraph",sep=""))
    filename <- file.path(out_track_dir,paste(name,".bed",sep=""))
    values <- gr$score
    bed <- data.frame(chr=seqnames(gr), start=as.integer(start(gr)-1), end=as.integer(end(gr)), value=values)
    bed <- bed[bed$value!=0,]
    write.table(bed, file=filename, append=FALSE, quote=FALSE, row.names=FALSE, col.names=FALSE, sep="\t")
    
    if(bigwig==TRUE)
    {
      message(paste(name,": Converting to BigWig",sep=""))
      cs <- tempfile(name)
      write.table(data.frame(chrs,chrlens),col.names=F,row.names=F,file=cs, quote=F)
      cmd <- paste("wigToBigWig",filename,cs,file.path(out_track_dir,paste(name,".bw",sep="")),sep=" ")
      cmd <- sprintf("%s %s",cmd,wigToBigWig_opt)
      message(cmd)
      system(cmd)
      file.remove(cs)
    }
  }
  
  doit <- mclapply(1:length(reads),function(x) writeBed(gr=covgr1[[x]],name=paste0(names(reads)[x])))
  
  doit <- mclapply(1:length(reads),function(x) writeBed(gr=covgr1.norm[[x]],name=paste0(names(reads)[x],"_Scaled")))
  
  return (NULL)
}

if (T) {
  args_tmp <- commandArgs(trailingOnly = F)
  scriptPath <- dirname(normalizePath(sub("--file=","",args_tmp[grep("--file",args_tmp)])))
  source_root <- dirname(dirname(scriptPath))
  parser <- ArgumentParser(description='diffChipSeq_lite')
  
  parser$add_argument("-n", "--ncpu", type="integer", required=FALSE,
                      dest="ncpu", default = 1,
                      help="number of cpus to utilize [1]")

  parser$add_argument("-s", "--exp_sheet_fn", type="character", required=TRUE,
                      dest="exp_sheet_fn",
                      help="BAM file name w/o whitespace")
  
  parser$add_argument("-c", "--ctrl", type="character", required=FALSE,
                      default="HCT116",
                      dest="ctrl",
                      help="control group name")
  
  parser$add_argument("-e", "--expr", type="character", required=FALSE,
                      dest="expr",
                      default="DKO",
                      help="experiment group name")
  
  parser$add_argument("-p", "--protein", type="character", required=FALSE,
                      dest="protein", default="NA",
                      help="protein antibody(tag)")
  
  parser$add_argument("-o", "--track_dir", type="character", required=FALSE,
                      default="./02_wkd/chipseq_bw_tracks",
                      dest="track_dir",
                      help="output track dir")
  
  parser$add_argument("-f", "--ftp_server", type="character", required=TRUE,
                      dest="ftp_server",
                      help="ftp server with password, no / at the end")
  
  parser$add_argument("-w", "--wigToBigWig_opt", type="character", required=FALSE,
                      dest="wigToBigWig_opt", default="",
                      help="wigToBigWig option")
  
  parser$add_argument("-u", "--uniq", type="integer", required=FALSE,
                      dest="uniq", default = 1,
                      help="unique reads in BAM [1]:Yes, 0: No (dup reads allowed)")
  
  
  args <- parser$parse_args()
} else { #debug
  args <- data.table(ncpu=12,
                     exp_sheet_fn="polyASeq_samples_all.csv",
                     ctrl='HCT116',
                     expr='DKO',
                     protein='NA',
                     track_dir="",
                     ftp_server="")
}

if (!dir.exists(args$track_dir)) {dir.create(args$track_dir)}

# --------------------------------------------------------------------
# 

# Settings
ncore <- args$ncpu
chrs <- handy::chrs()

samp2 <- as.data.table(readSampleInfo(args$exp_sheet_fn))

message('selecting two rows to compare with ...')

if (args$protein=="NA") {
  samp2 <- samp2[(group %in% c(args$expr,args$ctrl)),]
} else {
  samp2 <- samp2[(group %in% c(args$expr,args$ctrl) & protein == args$protein),]
}

samp2$label <- 'NA'
samp2[group==args$ctrl,label:='ctrl']
samp2[group==args$expr,label:='expr']

# -------------------------
message('load reads from bam files ...')
read2 <- getReads(samp=samp2,chrs=chrs,ncore=ncore)
read2 <- lapply(read2,sortSeqlevels)
read2 <- lapply(read2,sort)
if (args$uniq==1) {
  read2 <- lapply(read2,unique)
}

# Save bigWigs of coverages
track_suffix <- sprintf("%s_%s_%s",args$ctrl,args$expr,args$protein)

saveCov_compare(samp=samp2,
                reads=read2,
                out_track_dir=args$track_dir,
                bigwig=TRUE,
                server=args$ftp_server,
                ncore=ncore,
                track_suffix = track_suffix,
                wigToBigWig_opt=args$wigToBigWig_opt)
